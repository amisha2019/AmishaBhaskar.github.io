<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="https://vishnuduttsharma.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://vishnuduttsharma.github.io/" rel="alternate" type="text/html" /><updated>2024-09-19T12:21:57-07:00</updated><id>https://vishnuduttsharma.github.io/feed.xml</id><title type="html">Vishnu Dutt Sharma</title><subtitle>Vishnu Sharma</subtitle><author><name>Vishnu Dutt Sharma</name><email>vishnuds@umd.edu</email></author><entry><title type="html">Explaining Deep Reinforcement Learning models with Linear Model U-Trees</title><link href="https://vishnuduttsharma.github.io/https:/vishnudsharma.medium.com/explaining-deep-reinforcement-learning-models-with-linear-model-u-trees-64c7d788fe4f" rel="alternate" type="text/html" title="Explaining Deep Reinforcement Learning models with Linear Model U-Trees" /><published>2021-04-04T00:00:00-07:00</published><updated>2021-04-04T00:00:00-07:00</updated><id>https://vishnuduttsharma.github.io/https:/vishnudsharma.medium.com/lmut</id><content type="html" xml:base="https://vishnuduttsharma.github.io/https:/vishnudsharma.medium.com/explaining-deep-reinforcement-learning-models-with-linear-model-u-trees-64c7d788fe4f">&lt;p&gt;Read &lt;a href=&quot;https://vishnudsharma.medium.com/explaining-deep-reinforcement-learning-models-with-linear-model-u-trees-64c7d788fe4f&quot;&gt;this post at Medium&lt;/a&gt;. &lt;br /&gt;
A popular deep learning explainability approach is to approaximate the behavior of the pre-trained deep learning model into a less complex, but interpretable learning method. 
Decision trees are quite useful here because they are often easy to interpret, while also providing a good performance. In this post, I summarise a explanability method using 
Linear Model U-Trees (LMUTs) by &lt;em&gt;Guiliang Liu&lt;/em&gt;, &lt;em&gt;Oliver Schulte&lt;/em&gt;, &lt;em&gt;Wang Zhu&lt;/em&gt; and &lt;em&gt;Qingcan Li&lt;/em&gt; in their paper &lt;em&gt;Toward Interpretable Deep Reinforcement Learning with Linear Model U-Trees&lt;/em&gt;.&lt;/p&gt;</content><author><name>Vishnu Dutt Sharma</name><email>vishnuds@umd.edu</email></author><category term="Deep Learning" /><category term="Interpretability" /><category term="Explainability" /><category term="Machine Learning" /><summary type="html">Read this post at Medium. A popular deep learning explainability approach is to approaximate the behavior of the pre-trained deep learning model into a less complex, but interpretable learning method. Decision trees are quite useful here because they are often easy to interpret, while also providing a good performance. In this post, I summarise a explanability method using Linear Model U-Trees (LMUTs) by Guiliang Liu, Oliver Schulte, Wang Zhu and Qingcan Li in their paper Toward Interpretable Deep Reinforcement Learning with Linear Model U-Trees.</summary></entry><entry><title type="html">On Local Interpretable Model-agnostic Explanations</title><link href="https://vishnuduttsharma.github.io/https:/vishnudsharma.medium.com/on-local-interpretable-model-agnostic-explanations-e8b85dbae3a0" rel="alternate" type="text/html" title="On Local Interpretable Model-agnostic Explanations" /><published>2020-12-26T00:00:00-08:00</published><updated>2020-12-26T00:00:00-08:00</updated><id>https://vishnuduttsharma.github.io/https:/vishnudsharma.medium.com/lime</id><content type="html" xml:base="https://vishnuduttsharma.github.io/https:/vishnudsharma.medium.com/on-local-interpretable-model-agnostic-explanations-e8b85dbae3a0">&lt;p&gt;Read &lt;a href=&quot;https://vishnudsharma.medium.com/on-local-interpretable-model-agnostic-explanations-e8b85dbae3a0&quot;&gt;this post at Medium&lt;/a&gt;. &lt;br /&gt;
Local Interpretable Model-agnostic Explanations (LIME) is one of the most popular technique for deel learning explanability, as it covers a wide range of inputs types (e.g. images, text, tabular data) and treats the model as a black-box, which means it can be used with any deep learning model. In this post, I explain how LIME works  with the help of some intermediate outputs.&lt;/p&gt;</content><author><name>Vishnu Dutt Sharma</name><email>vishnuds@umd.edu</email></author><category term="Deep Learning" /><category term="Interpretability" /><category term="Explainability" /><category term="Machine Learning" /><summary type="html">Read this post at Medium. Local Interpretable Model-agnostic Explanations (LIME) is one of the most popular technique for deel learning explanability, as it covers a wide range of inputs types (e.g. images, text, tabular data) and treats the model as a black-box, which means it can be used with any deep learning model. In this post, I explain how LIME works with the help of some intermediate outputs.</summary></entry><entry><title type="html">Neural Networks: Mathematics and Interpretation</title><link href="https://vishnuduttsharma.github.io/https:/vishnudsharma.medium.com/neural-networks-mathematics-and-interpretation-229b4ba6785b" rel="alternate" type="text/html" title="Neural Networks: Mathematics and Interpretation" /><published>2018-12-21T00:00:00-08:00</published><updated>2018-12-21T00:00:00-08:00</updated><id>https://vishnuduttsharma.github.io/https:/vishnudsharma.medium.com/nn-maths</id><content type="html" xml:base="https://vishnuduttsharma.github.io/https:/vishnudsharma.medium.com/neural-networks-mathematics-and-interpretation-229b4ba6785b">&lt;p&gt;Read &lt;a href=&quot;https://vishnudsharma.medium.com/neural-networks-mathematics-and-interpretation-229b4ba6785b&quot;&gt;this post at Medium&lt;/a&gt;. &lt;br /&gt;
Neural Networks (NNs) are the basic units of deep learning model. Therefore, the first step towards understanding how deep learning models work is to understand how NNs work. In this post, I use a methoematical approach using plots and matrix algebra to shed light on how the elements of NN come together to generate a powerful learning mechanism.&lt;/p&gt;</content><author><name>Vishnu Dutt Sharma</name><email>vishnuds@umd.edu</email></author><category term="Neural Networks" /><category term="Machine Learning" /><summary type="html">Read this post at Medium. Neural Networks (NNs) are the basic units of deep learning model. Therefore, the first step towards understanding how deep learning models work is to understand how NNs work. In this post, I use a methoematical approach using plots and matrix algebra to shed light on how the elements of NN come together to generate a powerful learning mechanism.</summary></entry><entry><title type="html">Understanding what RNN learns: Part 2</title><link href="https://vishnuduttsharma.github.io/https:/vishnudsharma.medium.com/understanding-what-rnn-learns-part-2-50e5e7706c28" rel="alternate" type="text/html" title="Understanding what RNN learns: Part 2" /><published>2018-06-19T00:00:00-07:00</published><updated>2018-06-19T00:00:00-07:00</updated><id>https://vishnuduttsharma.github.io/https:/vishnudsharma.medium.com/rnn-part2</id><content type="html" xml:base="https://vishnuduttsharma.github.io/https:/vishnudsharma.medium.com/understanding-what-rnn-learns-part-2-50e5e7706c28">&lt;p&gt;Read &lt;a href=&quot;https://vishnudsharma.medium.com/understanding-what-rnn-learns-part-2-50e5e7706c28&quot;&gt;this post at Medium&lt;/a&gt;. &lt;br /&gt;
Building upon the &lt;a href=&quot;https://vishnudsharma.medium.com/understanding-what-rnn-learns-part-1-5f1b23b5f7b4&quot;&gt;previous post&lt;/a&gt;, in this part I use layer fusion to explain the wroking of vanilla Recurrent Neural Networks using embeddings.&lt;/p&gt;</content><author><name>Vishnu Dutt Sharma</name><email>vishnuds@umd.edu</email></author><category term="Deep Learning" /><category term="RNN" /><category term="Embedding" /><category term="Keras" /><category term="Machine Learning" /><summary type="html">Read this post at Medium. Building upon the previous post, in this part I use layer fusion to explain the wroking of vanilla Recurrent Neural Networks using embeddings.</summary></entry><entry><title type="html">Understanding what RNN learns: Part 1</title><link href="https://vishnuduttsharma.github.io/https:/vishnudsharma.medium.com/understanding-what-rnn-learns-part-1-5f1b23b5f7b4" rel="alternate" type="text/html" title="Understanding what RNN learns: Part 1" /><published>2018-06-18T00:00:00-07:00</published><updated>2018-06-18T00:00:00-07:00</updated><id>https://vishnuduttsharma.github.io/https:/vishnudsharma.medium.com/rnn-part1</id><content type="html" xml:base="https://vishnuduttsharma.github.io/https:/vishnudsharma.medium.com/understanding-what-rnn-learns-part-1-5f1b23b5f7b4">&lt;p&gt;Read &lt;a href=&quot;https://vishnudsharma.medium.com/understanding-what-rnn-learns-part-1-5f1b23b5f7b4&quot;&gt;this post at Medium&lt;/a&gt;. &lt;br /&gt;
Recurrent Neural Networks (RNNs) are difficult to explain or interpret because of both the underlying neural networks and their recurrent nature. In this post, I look at the elements of RNNs to explain how they work individually and in conjunction with other elements.&lt;/p&gt;</content><author><name>Vishnu Dutt Sharma</name><email>vishnuds@umd.edu</email></author><category term="Deep Learning" /><category term="RNN" /><category term="Keras" /><category term="Machine Learning" /><summary type="html">Read this post at Medium. Recurrent Neural Networks (RNNs) are difficult to explain or interpret because of both the underlying neural networks and their recurrent nature. In this post, I look at the elements of RNNs to explain how they work individually and in conjunction with other elements.</summary></entry><entry><title type="html">Keras Functional models: Few pointers for debugging</title><link href="https://vishnuduttsharma.github.io/https:/vishnudsharma.medium.com/keras-functional-models-few-pointers-for-debugging-c58072bbcba9" rel="alternate" type="text/html" title="Keras Functional models: Few pointers for debugging" /><published>2012-02-18T00:00:00-08:00</published><updated>2012-02-18T00:00:00-08:00</updated><id>https://vishnuduttsharma.github.io/https:/vishnudsharma.medium.com/keras</id><content type="html" xml:base="https://vishnuduttsharma.github.io/https:/vishnudsharma.medium.com/keras-functional-models-few-pointers-for-debugging-c58072bbcba9">&lt;p&gt;Read &lt;a href=&quot;https://vishnudsharma.medium.com/keras-functional-models-few-pointers-for-debugging-c58072bbcba9&quot;&gt;this post at Medium&lt;/a&gt;. &lt;br /&gt;
I leaned the ropes of deep learning model building with &lt;a href=&quot;https://keras.io/&quot;&gt;Keras&lt;/a&gt;. It’s easy to learn and use, and gives the user options to try many useful APIs like early stopping, scheduling learning rate, etc. As a beginner, you may want to familiarize yourself with some basics for debugging. In this post, I list down a few things that I found useful for that.&lt;/p&gt;</content><author><name>Vishnu Dutt Sharma</name><email>vishnuds@umd.edu</email></author><category term="Deep Learning" /><category term="Keras" /><category term="Machine Learning" /><summary type="html">Read this post at Medium. I leaned the ropes of deep learning model building with Keras. It’s easy to learn and use, and gives the user options to try many useful APIs like early stopping, scheduling learning rate, etc. As a beginner, you may want to familiarize yourself with some basics for debugging. In this post, I list down a few things that I found useful for that.</summary></entry></feed>